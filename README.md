# Regression Property Inference Attacks & Defense
Code for the research paper "Property Inference as a Regression Problem: Attacks and Defense"
https://doi.org/10.5220/0012863800003767

## Setup
* Locally (in virtual environment with python 3.10.9):
`pip install -r requirements.txt`
* Install a (remote) server environment with conda and jupyter:
```
conda create --name "pia-tf" python=3.10.9 ipython
conda activate pia-tf
conda install jupyter pip
pip install pandas numpy tensorflow keras-tuner scikit-learn pillow
conda deactivate && python -m ipykernel install --user --name pia-tf
nano ~/.local/share/jupyter/kernels/pia-tf/kernel.json
```
last command: add the jupyter kernel manually in case it has not been added to list.
Make sure to change the path to the python executable to the one in the conda environment
(e.g. `/home/username/anaconda3/envs/pia-tf/bin/python`).

## Get started
The experiments in this repository are mainly based on three data sets: Adult, CIFAR-10 and UTKFace.
### Adult-specific preperations:
While the attack data sets (see research paper above for details) for CIFAR-10 and UTKFace are existing data sets, the attack data set for Adult was generated by  `adult_generate-synthetic-data.py`. The script does not need to be re-run, its results are saved in `src/adult/data/syn_data-new.csv`.
### UTKFace-specific preparations:
Download the UTKFace data set from https://susanqq.github.io/UTKFace/ (aligned and cropped) and paste the images into `src/utkface/data/utkface`.
Download the *Labelled Faces in the Wild (LFW)* data set from https://www.kaggle.com/datasets/jessicali9530/lfw-dataset and paste the images into `src/utkface/data/lfw-deepfunneled`.
### Create shadow model outputs to train adversary
* Adversaries are saved in `<dataset>/models`. Some white-box adversaries were too large for this repository and must be retrained using shadow models.
* If new adversaries should be trained, shadow models need to be created first.
* Run `<dataset>_generate_shadow_models_outputs.py` script -> might take a long time
	* for white-box adversaries, models must be saved (set `save_models = True` in script)
* Code for training an adversary is in the corresponding `<dataset>.ipynb` notebook
### Run (black-box) defense experiment
* run `<dataset>_defense_experiment.py` -> might take a long time
### Generalizability experiment
* To test whether the black-box defense generalizes well to other adversary instances with the same goal, an additional experiment has been performed in `generalizability.ipynb`

## Troubleshooting
If keras is not able to load an adversary model, it usually helps to first create a fresh model with the adversary architecture and then load the weights of the saved model:
```
from utk_functions import utk_adversary

adv = utk_adversary()
adv.load_weights('utkface/models/adv_v2_0.63_r2.keras')
```
